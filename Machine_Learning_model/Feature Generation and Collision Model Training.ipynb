{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to generate the d_min, time_to_closest and relative velocity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def append_collision_features(df, threshold=1000):\n",
    "    new_rows = []\n",
    "\n",
    "    # group by epoch\n",
    "    for epoch, group in df.groupby(\"epoch\"):\n",
    "        objs = group.to_dict(\"records\")\n",
    "\n",
    "        for i, obj1 in enumerate(objs):\n",
    "            r1 = np.array([obj1[\"x\"], obj1[\"y\"], obj1[\"z\"]])\n",
    "            v1 = np.array([obj1[\"vx\"], obj1[\"vy\"], obj1[\"vz\"]])\n",
    "\n",
    "            closest_dist = np.inf\n",
    "            closest_t = None\n",
    "            closest_vel = None\n",
    "\n",
    "            for j, obj2 in enumerate(objs):\n",
    "                if i == j:  # skip self\n",
    "                    continue\n",
    "\n",
    "                r2 = np.array([obj2[\"x\"], obj2[\"y\"], obj2[\"z\"]])\n",
    "                v2 = np.array([obj2[\"vx\"], obj2[\"vy\"], obj2[\"vz\"]])\n",
    "\n",
    "                r_rel = r1 - r2\n",
    "                v_rel = v1 - v2\n",
    "\n",
    "                # time of closest approach\n",
    "                if np.linalg.norm(v_rel) > 0:\n",
    "                    t_star = -np.dot(r_rel, v_rel) / np.linalg.norm(v_rel) ** 2\n",
    "                    if t_star < 0:  \n",
    "                        t_star = 0\n",
    "                else:\n",
    "                    t_star = 0\n",
    "\n",
    "                r_closest = r_rel + v_rel * t_star\n",
    "                d_min = np.linalg.norm(r_closest)\n",
    "\n",
    "                if d_min < closest_dist:\n",
    "                    closest_dist = d_min\n",
    "                    closest_t = t_star\n",
    "                    closest_vel = np.linalg.norm(v_rel)\n",
    "\n",
    "            # create updated row with appended features\n",
    "            updated_row = obj1.copy()\n",
    "            updated_row.update({\n",
    "                \"d_min\": closest_dist,\n",
    "                \"time_to_closest\": closest_t,\n",
    "                \"rel_velocity\": closest_vel,\n",
    "                \"collision_risk\": 1 if closest_dist < threshold else 0\n",
    "            })\n",
    "            new_rows.append(updated_row)\n",
    "\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_space_data = pd.read_csv(\"Space_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ml_features(df):\n",
    "    \"\"\"\n",
    "    Generate leakage-free, predictive features for collision risk modeling.\n",
    "    Each row is an object at an epoch, with aggregated features relative to all other objects.\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "\n",
    "    for epoch, group in df.groupby(\"epoch\"):\n",
    "        objs = group.to_dict(\"records\")\n",
    "\n",
    "        for i, obj1 in enumerate(objs):\n",
    "            # skip object if it has zero values in any key field\n",
    "            if any(obj1[f] == 0 for f in [\"x\",\"y\",\"z\",\"vx\",\"vy\",\"vz\"]):\n",
    "                continue\n",
    "\n",
    "            r1 = np.array([obj1[\"x\"], obj1[\"y\"], obj1[\"z\"]], dtype=float)\n",
    "            v1 = np.array([obj1[\"vx\"], obj1[\"vy\"], obj1[\"vz\"]], dtype=float)\n",
    "\n",
    "            features_list = []\n",
    "\n",
    "            for j, obj2 in enumerate(objs):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                # skip if object2 has zero values\n",
    "                if any(obj2[f] == 0 for f in [\"x\",\"y\",\"z\",\"vx\",\"vy\",\"vz\"]):\n",
    "                    continue\n",
    "\n",
    "                r2 = np.array([obj2[\"x\"], obj2[\"y\"], obj2[\"z\"]], dtype=float)\n",
    "                v2 = np.array([obj2[\"vx\"], obj2[\"vy\"], obj2[\"vz\"]], dtype=float)\n",
    "\n",
    "                delta_r = r1 - r2\n",
    "                delta_v = v1 - v2\n",
    "                rel_vel = np.linalg.norm(delta_v)\n",
    "\n",
    "                # angle between velocity vectors\n",
    "                dot_prod = np.dot(v1, v2)\n",
    "                norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "                angle_vel = np.arccos(np.clip(dot_prod / norm_prod, -1, 1)) if norm_prod != 0 else 0\n",
    "\n",
    "                features_list.append({\n",
    "                    \"rel_velocity\": rel_vel,\n",
    "                    \"delta_x\": delta_r[0],\n",
    "                    \"delta_y\": delta_r[1],\n",
    "                    \"delta_z\": delta_r[2],\n",
    "                    \"angle_vel\": angle_vel\n",
    "                })\n",
    "\n",
    "            if not features_list:\n",
    "                continue  # skip if no valid comparisons\n",
    "\n",
    "            # aggregate features across all other objects\n",
    "            row_features = obj1.copy()\n",
    "            row_features.update({\n",
    "                \"rel_velocity_max\": max(f[\"rel_velocity\"] for f in features_list),\n",
    "                \"rel_velocity_mean\": np.mean([f[\"rel_velocity\"] for f in features_list]),\n",
    "                \"delta_x_min\": min(f[\"delta_x\"] for f in features_list),\n",
    "                \"delta_y_min\": min(f[\"delta_y\"] for f in features_list),\n",
    "                \"delta_z_min\": min(f[\"delta_z\"] for f in features_list),\n",
    "                \"angle_vel_max\": max(f[\"angle_vel\"] for f in features_list),\n",
    "                \"angle_vel_mean\": np.mean([f[\"angle_vel\"] for f in features_list])\n",
    "            })\n",
    "\n",
    "            # keep the label for supervised training\n",
    "            row_features[\"collision_risk\"] = obj1.get(\"collision_risk\", 0)\n",
    "\n",
    "            new_rows.append(row_features)\n",
    "\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_data = generate_ml_features(new_space_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_data.drop(['Unnamed: 0','d_min','time_to_closest'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['classificationMarking_x', 'object_id', 'pointId', 'x', 'y', 'z', 'vx',\n",
       "       'vy', 'vz', 'source_x', 'pointStartTime', 'pointEndTime',\n",
       "       'referenceFrame', 'source_y', 'epoch', 'rel_velocity', 'collision_risk',\n",
       "       'rel_velocity_max', 'rel_velocity_mean', 'delta_x_min', 'delta_y_min',\n",
       "       'delta_z_min', 'angle_vel_max', 'angle_vel_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_data.to_csv(\"Space_Data_with_collision_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_data = pd.read_csv(\"Space_Data_with_collision_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>classificationMarking_x</th>\n",
       "      <th>object_id</th>\n",
       "      <th>pointId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>...</th>\n",
       "      <th>epoch</th>\n",
       "      <th>rel_velocity</th>\n",
       "      <th>collision_risk</th>\n",
       "      <th>rel_velocity_max</th>\n",
       "      <th>rel_velocity_mean</th>\n",
       "      <th>delta_x_min</th>\n",
       "      <th>delta_y_min</th>\n",
       "      <th>delta_z_min</th>\n",
       "      <th>angle_vel_max</th>\n",
       "      <th>angle_vel_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>57f03102-f98b-43ad-93cb-3482c2ffd27f</td>\n",
       "      <td>eb1f9421-fe2f-4738-ada4-1c4771860a43</td>\n",
       "      <td>1300.680962</td>\n",
       "      <td>10966.10884</td>\n",
       "      <td>-5347.317939</td>\n",
       "      <td>-1.064615</td>\n",
       "      <td>2.438418</td>\n",
       "      <td>4.753137</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-08-10 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>976b0dab-713d-4696-947e-585686ba34da</td>\n",
       "      <td>5cec3e2e-96cf-4fd9-b7ab-7e4e7fc81c85</td>\n",
       "      <td>1300.680902</td>\n",
       "      <td>10966.10882</td>\n",
       "      <td>-5347.317995</td>\n",
       "      <td>-1.064615</td>\n",
       "      <td>2.438418</td>\n",
       "      <td>4.753137</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-08-10 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>57f03102-f98b-43ad-93cb-3482c2ffd27f</td>\n",
       "      <td>a7099044-7e3a-402c-a464-bf0e7648b8a6</td>\n",
       "      <td>1173.489694</td>\n",
       "      <td>11243.06909</td>\n",
       "      <td>-4768.922726</td>\n",
       "      <td>-1.055470</td>\n",
       "      <td>2.176382</td>\n",
       "      <td>4.884289</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-08-10 00:02:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>976b0dab-713d-4696-947e-585686ba34da</td>\n",
       "      <td>77972af7-c988-4778-9e1f-96afcb622469</td>\n",
       "      <td>1173.489633</td>\n",
       "      <td>11243.06907</td>\n",
       "      <td>-4768.922784</td>\n",
       "      <td>-1.055470</td>\n",
       "      <td>2.176382</td>\n",
       "      <td>4.884289</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-08-10 00:02:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>U</td>\n",
       "      <td>57f03102-f98b-43ad-93cb-3482c2ffd27f</td>\n",
       "      <td>6d12cdf0-0166-490a-8cf2-516cbebfcf50</td>\n",
       "      <td>1047.309966</td>\n",
       "      <td>11488.16798</td>\n",
       "      <td>-4175.695143</td>\n",
       "      <td>-1.047779</td>\n",
       "      <td>1.907534</td>\n",
       "      <td>5.000278</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-08-10 00:04:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 classificationMarking_x                             object_id  \\\n",
       "0           0                       U  57f03102-f98b-43ad-93cb-3482c2ffd27f   \n",
       "1           1                       U  976b0dab-713d-4696-947e-585686ba34da   \n",
       "2           2                       U  57f03102-f98b-43ad-93cb-3482c2ffd27f   \n",
       "3           3                       U  976b0dab-713d-4696-947e-585686ba34da   \n",
       "4           4                       U  57f03102-f98b-43ad-93cb-3482c2ffd27f   \n",
       "\n",
       "                                pointId            x            y  \\\n",
       "0  eb1f9421-fe2f-4738-ada4-1c4771860a43  1300.680962  10966.10884   \n",
       "1  5cec3e2e-96cf-4fd9-b7ab-7e4e7fc81c85  1300.680902  10966.10882   \n",
       "2  a7099044-7e3a-402c-a464-bf0e7648b8a6  1173.489694  11243.06909   \n",
       "3  77972af7-c988-4778-9e1f-96afcb622469  1173.489633  11243.06907   \n",
       "4  6d12cdf0-0166-490a-8cf2-516cbebfcf50  1047.309966  11488.16798   \n",
       "\n",
       "             z        vx        vy        vz  ...                      epoch  \\\n",
       "0 -5347.317939 -1.064615  2.438418  4.753137  ...  2025-08-10 00:00:00+00:00   \n",
       "1 -5347.317995 -1.064615  2.438418  4.753137  ...  2025-08-10 00:00:00+00:00   \n",
       "2 -4768.922726 -1.055470  2.176382  4.884289  ...  2025-08-10 00:02:00+00:00   \n",
       "3 -4768.922784 -1.055470  2.176382  4.884289  ...  2025-08-10 00:02:00+00:00   \n",
       "4 -4175.695143 -1.047779  1.907534  5.000278  ...  2025-08-10 00:04:00+00:00   \n",
       "\n",
       "  rel_velocity collision_risk rel_velocity_max rel_velocity_mean delta_x_min  \\\n",
       "0          0.0              1              0.0               0.0    0.000060   \n",
       "1          0.0              1              0.0               0.0   -0.000060   \n",
       "2          0.0              1              0.0               0.0    0.000061   \n",
       "3          0.0              1              0.0               0.0   -0.000061   \n",
       "4          0.0              1              0.0               0.0    0.000062   \n",
       "\n",
       "   delta_y_min  delta_z_min  angle_vel_max  angle_vel_mean  \n",
       "0      0.00002     0.000056            0.0             0.0  \n",
       "1     -0.00002    -0.000056            0.0             0.0  \n",
       "2      0.00002     0.000058            0.0             0.0  \n",
       "3     -0.00002    -0.000058            0.0             0.0  \n",
       "4      0.00001     0.000059            0.0             0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_data.drop(['Unnamed: 0','classificationMarking_x','pointId'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = space_data[space_data['epoch'] < '2025-08-24']\n",
    "test_df  = space_data[space_data['epoch'] >= '2025-08-24']\n",
    "\n",
    "X_train = train_df[[\"rel_velocity_max\",\"rel_velocity_mean\",\n",
    "                    \"delta_x_min\",\"delta_y_min\",\"delta_z_min\",\n",
    "                    \"angle_vel_max\",\"angle_vel_mean\"]]\n",
    "y_train = train_df[\"collision_risk\"]\n",
    "\n",
    "X_test = test_df[[\"rel_velocity_max\",\"rel_velocity_mean\",\n",
    "                  \"delta_x_min\",\"delta_y_min\",\"delta_z_min\",\n",
    "                  \"angle_vel_max\",\"angle_vel_mean\"]]\n",
    "y_test = test_df[\"collision_risk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70     18120\n",
      "           1       0.94      0.94      0.94     90312\n",
      "\n",
      "    accuracy                           0.90    108432\n",
      "   macro avg       0.82      0.82      0.82    108432\n",
      "weighted avg       0.90      0.90      0.90    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8980005902316659\n",
      "Precision:  0.9395953051851523\n",
      "Recall  0.9378266454070334\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred_rf)\n",
    "print(\"Accuracy: \" , accuracy)\n",
    "precision = precision_score(y_test,y_pred_rf)\n",
    "print(\"Precision: \" ,precision)\n",
    "recall = recall_score(y_test,y_pred_rf)\n",
    "print(\"Recall \" ,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387101421969033"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiimi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:44:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiimi\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.71     18120\n",
      "           1       0.93      0.97      0.95     90312\n",
      "\n",
      "    accuracy                           0.91    108432\n",
      "   macro avg       0.87      0.80      0.83    108432\n",
      "weighted avg       0.91      0.91      0.91    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb = xgb.XGBClassifier(n_estimators=200, scale_pos_weight=1)  # tune scale_pos_weight if imbalance\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(\"XGBoost:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9140382912793271\n",
      "Precision:  0.93035909752702\n",
      "Recall  0.9693506953671716\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred_xgb)\n",
    "print(\"Accuracy: \" , accuracy)\n",
    "precision = precision_score(y_test,y_pred_xgb)\n",
    "print(\"Precision: \" ,precision)\n",
    "recall = recall_score(y_test,y_pred_xgb)\n",
    "print(\"Recall \" ,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9494547446165859"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70     18120\n",
      "           1       0.94      0.94      0.94     90312\n",
      "\n",
      "    accuracy                           0.90    108432\n",
      "   macro avg       0.82      0.82      0.82    108432\n",
      "weighted avg       0.90      0.90      0.90    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth = 10, random_state= 60, min_samples_split=6,min_samples_leaf=8)\n",
    "rf2.fit(X_train, y_train)\n",
    "y_pred_rf2 = rf2.predict(X_test)\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.54      0.67     18120\n",
      "           1       0.92      0.98      0.95     90312\n",
      "\n",
      "    accuracy                           0.91    108432\n",
      "   macro avg       0.90      0.76      0.81    108432\n",
      "weighted avg       0.91      0.91      0.90    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf2 = rf2.predict(X_test)\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9112070237568246\n",
      "Precision:  0.915152201206084\n",
      "Recall  0.9846864204092479\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = accuracy_score(y_test,y_pred_rf2)\n",
    "print(\"Accuracy: \" , accuracy2)\n",
    "precision2 = precision_score(y_test,y_pred_rf2)\n",
    "print(\"Precision: \" ,precision2)\n",
    "recall2 = recall_score(y_test,y_pred_rf2)\n",
    "print(\"Recall \" ,recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486468322968115"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiimi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiimi\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70     18120\n",
      "           1       0.92      0.98      0.95     90312\n",
      "\n",
      "    accuracy                           0.92    108432\n",
      "   macro avg       0.90      0.78      0.82    108432\n",
      "weighted avg       0.91      0.92      0.91    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb2 = xgb.XGBClassifier(n_estimators=100, random_state= 60, learning_rate=0.1, max_depth=5, eta=0.2, subsample=0.5, reg_lambda=0.3)\n",
    "xgb2.fit(X_train, y_train)\n",
    "y_pred_xgb2 = xgb2.predict(X_test)\n",
    "print(\"XGBoost:\\n\", classification_report(y_test, y_pred_xgb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.915762874428213\n",
      "Precision:  0.921625046744505\n",
      "Recall  0.9824054389228453\n"
     ]
    }
   ],
   "source": [
    "accuracy3 = accuracy_score(y_test,y_pred_xgb2)\n",
    "print(\"Accuracy: \" , accuracy3)\n",
    "precision3 = precision_score(y_test,y_pred_xgb2)\n",
    "print(\"Precision: \" ,precision3)\n",
    "recall3 = recall_score(y_test,y_pred_xgb2)\n",
    "print(\"Recall \" ,recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510451280951872"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model2.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'random_forest_model2.joblib'\n",
    "joblib.dump(rf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiimi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:55:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiimi\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71     18120\n",
      "           1       0.92      0.98      0.95     90312\n",
      "\n",
      "    accuracy                           0.92    108432\n",
      "   macro avg       0.89      0.79      0.83    108432\n",
      "weighted avg       0.91      0.92      0.91    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb3 = xgb.XGBClassifier(n_estimators=200, random_state= 60, learning_rate=0.1, max_depth=5, eta=0.5)\n",
    "xgb3.fit(X_train, y_train)\n",
    "y_pred_xgb3 = xgb3.predict(X_test)\n",
    "print(\"XGBoost:\\n\", classification_report(y_test, y_pred_xgb3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9178747971078648\n",
      "Precision:  0.9249287496476631\n",
      "Recall  0.9810213482150766\n"
     ]
    }
   ],
   "source": [
    "accuracy4 = accuracy_score(y_test,y_pred_xgb3)\n",
    "print(\"Accuracy: \" , accuracy4)\n",
    "precision4 = precision_score(y_test,y_pred_xgb3)\n",
    "print(\"Precision: \" ,precision4)\n",
    "recall4 = recall_score(y_test,y_pred_xgb3)\n",
    "print(\"Recall \" ,recall4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521496391744267"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model2.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'xgb_model2.joblib'\n",
    "joblib.dump(xgb3, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.42      0.58     18120\n",
      "           1       0.90      0.99      0.94     90312\n",
      "\n",
      "    accuracy                           0.90    108432\n",
      "   macro avg       0.91      0.71      0.76    108432\n",
      "weighted avg       0.90      0.90      0.88    108432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=200, max_depth = 5, random_state= 60, min_samples_split=5,min_samples_leaf=5)\n",
    "rf3.fit(X_train, y_train)\n",
    "y_pred_rf3 = rf3.predict(X_test)\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.89760402833112\n",
      "Precision:  0.8958035598285046\n",
      "Recall  0.9925037647267251\n"
     ]
    }
   ],
   "source": [
    "accuracy5 = accuracy_score(y_test,y_pred_rf3)\n",
    "print(\"Accuracy: \" , accuracy5)\n",
    "precision5 = precision_score(y_test,y_pred_rf3)\n",
    "print(\"Precision: \" ,precision5)\n",
    "recall5 = recall_score(y_test,y_pred_rf3)\n",
    "print(\"Recall \" ,recall5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = joblib.load('random_forest_model2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Row Number':X_test.index,'predictions':rf_model_predictions}).to_csv('RandomForestPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([413623, 413624, 413625, 413626, 413627, 413628, 413629, 413630,\n",
       "            413631, 413632,\n",
       "            ...\n",
       "            522045, 522046, 522047, 522048, 522049, 522050, 522051, 522052,\n",
       "            522053, 522054],\n",
       "           dtype='int64', length=108432)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Row Number':X_test.index,'predictions':y_pred_xgb3}).to_csv('XGBoostPredictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
